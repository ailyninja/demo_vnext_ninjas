{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0729fd1",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": "\n# Light Forecasting Demo (with Dummy Data)\n\nThis notebook generates a realistic synthetic daily time series in the **first cell**, performs exploratory analysis, and runs a few **lightweight forecasting baselines** (naive, seasonal naive, moving average, simple exponential smoothing) plus a **Fourier + trend regression**. Charts use **matplotlib** only.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03445284",
      "metadata": {},
      "source": "\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Reproducibility\nrng = np.random.default_rng(42)\n\n# Create daily dates (about 4.5 years ending today)\nend = pd.Timestamp.today().normalize()\nstart = end - pd.Timedelta(days=4*365 + 240)\nds = pd.date_range(start, end, freq='D')\n\n# Build components\nn = len(ds)\nt = np.arange(n)\n\n# Trend (mild quadratic)\ntrend = 0.02 * t + 0.00005 * (t**2)\n\n# Weekly seasonality (period 7)\nweekly = 3 * np.sin(2 * np.pi * t / 7) + 1.5 * np.cos(2 * np.pi * 2 * t / 7)\n\n# Yearly seasonality (period ~365.25)\nyearly = 8 * np.sin(2 * np.pi * t / 365.25) + 4 * np.cos(2 * np.pi * 3 * t / 365.25)\n\n# Random noise\nnoise = rng.normal(0, 2.5, size=n)\n\n# Occasional promo/event lifts\npromo = np.zeros(n)\nfor _ in range(12):\n    start_idx = rng.integers(0, n-14)\n    length = rng.integers(3, 10)\n    promo[start_idx:start_idx+length] += rng.normal(12, 3)\n\n# Occasional outliers\noutliers = np.zeros(n)\noutlier_idx = rng.choice(n, size=10, replace=False)\noutliers[outlier_idx] = rng.normal(25, 6, size=10) * rng.choice([-1,1], size=10)\n\n# Base level\nbase = 50\n\n# Final series\ny = base + trend + weekly + yearly + promo + outliers + noise\n\ndf = pd.DataFrame({'ds': ds, 'y': y})\ndf = df.set_index('ds').asfreq('D')\n\nprint(\"Data shape:\", df.shape)\ndf.head()",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "154dd6b1",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Quick look at the data\nWe'll peek at the head/tail and basic statistics.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c0fefe",
      "metadata": {},
      "source": "\ndisplay(df.head())\ndisplay(df.tail())\ndisplay(df.describe())\n\nplt.figure(figsize=(10,4))\nplt.plot(df.index, df['y'])\nplt.title('Raw Daily Series')\nplt.xlabel('Date')\nplt.ylabel('y')\nplt.grid(True)\nplt.show()",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "914a251e",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Rolling averages and variability\nA quick check of rolling mean and rolling standard deviation.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255889b8",
      "metadata": {},
      "source": "\nroll = df['y'].rolling(30, min_periods=1)\nplt.figure(figsize=(10,4))\nplt.plot(df.index, df['y'], label='y', alpha=0.6)\nplt.plot(df.index, roll.mean(), label='30d mean')\nplt.plot(df.index, roll.std(), label='30d std')\nplt.title('Rolling 30-Day Mean & Std')\nplt.xlabel('Date')\nplt.ylabel('Value')\nplt.grid(True)\nplt.legend()\nplt.show()",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5b47ab46",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Seasonality views\nDaily (day-of-week) and monthly patterns to visualize weekly and annual seasonality.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aff1b75",
      "metadata": {},
      "source": "\ndow = df.copy()\ndow['dow'] = dow.index.dayofweek\ndow_mean = dow.groupby('dow')['y'].mean()\n\nplt.figure(figsize=(8,3))\nplt.plot(dow_mean.index, dow_mean.values, marker='o')\nplt.xticks(range(7), ['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])\nplt.title('Average by Day of Week')\nplt.xlabel('Day of Week')\nplt.ylabel('Average y')\nplt.grid(True)\nplt.show()",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f532aa2",
      "metadata": {},
      "source": "\nmo = df.copy()\nmo['month'] = mo.index.month\nmo_mean = mo.groupby('month')['y'].mean()\n\nplt.figure(figsize=(8,3))\nplt.plot(mo_mean.index, mo_mean.values, marker='o')\nplt.xticks(range(1,13))\nplt.title('Average by Month')\nplt.xlabel('Month')\nplt.ylabel('Average y')\nplt.grid(True)\nplt.show()",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "49c08af2",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Train / Test split\nWe'll hold out the last 90 days for evaluation.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d308141",
      "metadata": {},
      "source": "\nhorizon = 90\ntrain = df.iloc[:-horizon].copy()\ntest = df.iloc[-horizon:].copy()\nprint(\"Train:\", train.shape, \" Test:\", test.shape)",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53692ab7",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Baseline forecasts\nWe'll implement a few simple baselines:\n- **Naive**: Forecast equals the last observed value from the train set\n- **Seasonal Naive (weekly)**: Forecast equals the value from 7 days ago\n- **Moving Average (7-day)**: Rolling average updates one step ahead",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88081e72",
      "metadata": {},
      "source": "\ndef mae(y_true, y_pred):\n    return float(np.mean(np.abs(y_true - y_pred)))\n\ndef rmse(y_true, y_pred):\n    return float(np.sqrt(np.mean((y_true - y_pred)**2)))\n\ndef mape(y_true, y_pred):\n    eps = 1e-8\n    return float(np.mean(np.abs((y_true - y_pred) / (np.maximum(np.abs(y_true), eps)))) * 100)\n\ny_train = train['y']\ny_test = test['y']\n\n# Naive\nnaive_forecast = pd.Series(y_train.iloc[-1], index=test.index)\n\n# Seasonal naive (weekly)\nseasonal_lag = 7\nseasonal_naive = pd.Series(index=test.index, dtype=float)\nfor i, ts in enumerate(test.index):\n    ref = ts - pd.Timedelta(days=seasonal_lag)\n    if ref in df.index:\n        seasonal_naive.iloc[i] = df.loc[ref, 'y']\n    else:\n        seasonal_naive.iloc[i] = y_train.iloc[-1]\n\nprint(\"Naive  - RMSE:\", rmse(y_test, naive_forecast), \"MAE:\", mae(y_test, naive_forecast), \"MAPE:\", mape(y_test, naive_forecast))\nprint(\"S-Naive- RMSE:\", rmse(y_test, seasonal_naive), \"MAE:\", mae(y_test, seasonal_naive), \"MAPE:\", mape(y_test, seasonal_naive))",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c265e142",
      "metadata": {},
      "source": "\n# Moving average (7-day), one-step ahead updating with observed values\nwindow = 7\nhist = y_train.copy()\nma_preds = []\nfor ts in test.index:\n    if len(hist) >= window:\n        ma_preds.append(hist.iloc[-window:].mean())\n    else:\n        ma_preds.append(hist.mean())\n    # After predicting, \"observe\" the true test value to update rolling history\n    hist = pd.concat([hist, pd.Series([y_test.loc[ts]], index=[ts])])\n\nma_forecast = pd.Series(ma_preds, index=test.index)\n\nprint(\"MA(7)  - RMSE:\", rmse(y_test, ma_forecast), \"MAE:\", mae(y_test, ma_forecast), \"MAPE:\", mape(y_test, ma_forecast))",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d895773b",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Simple Exponential Smoothing (SES)\nWe'll tune \\(\\alpha\\) by grid search (no external libraries) using one-step-ahead test prediction.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669fbe89",
      "metadata": {},
      "source": "\ndef ses_one_step(train_series, test_series, alpha):\n    # initialize level using first train observation\n    S = float(train_series.iloc[0])\n    # fit on train\n    for y in train_series.iloc[1:]:\n        S = alpha * float(y) + (1 - alpha) * S\n    # one-step ahead predictions across test\n    preds = []\n    for y in test_series:\n        preds.append(S)  # forecast for this step\n        S = alpha * float(y) + (1 - alpha) * S  # update after observing true\n    return np.array(preds), S  # return final level too\n\nalphas = np.linspace(0.05, 0.95, 19)\nbest_alpha, best_rmse = None, float('inf')\nbest_preds, best_S = None, None\n\nfor a in alphas:\n    preds, S_final = ses_one_step(y_train, y_test, a)\n    r = rmse(y_test.values, preds)\n    if r < best_rmse:\n        best_rmse = r\n        best_alpha = a\n        best_preds = preds\n        best_S = S_final\n\nses_forecast = pd.Series(best_preds, index=test.index)\n\nprint(f\"Best alpha: {best_alpha:.2f}\")\nprint(\"SES     - RMSE:\", rmse(y_test, ses_forecast), \"MAE:\", mae(y_test, ses_forecast), \"MAPE:\", mape(y_test, ses_forecast))",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7a21a24f",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Fourier + Trend Regression\nWe fit a simple linear model (via least squares) with:\n- Intercept, linear and quadratic trend\n- Weekly Fourier terms (order=3)\n- Yearly Fourier terms (order=5)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ac29df",
      "metadata": {},
      "source": "\ndef fourier_features(t, period, order):\n    X = []\n    for k in range(1, order+1):\n        X.append(np.sin(2*np.pi*k*t/period))\n        X.append(np.cos(2*np.pi*k*t/period))\n    return np.column_stack(X) if X else np.zeros((len(t),0))\n\n# Build global time index\nt_all = np.arange(len(df))\nt_train = np.arange(len(train))\nt_test = np.arange(len(train), len(df))\n\n# Design matrix\nX_train_parts = [\n    np.ones_like(t_train),\n    t_train,\n    t_train**2,\n    fourier_features(t_train, period=7, order=3),\n    fourier_features(t_train, period=365.25, order=5)\n]\nX_train = np.column_stack(X_train_parts)\n\ny_tr = y_train.values\nbeta, *_ = np.linalg.lstsq(X_train, y_tr, rcond=None)\n\n# Predict on test\nX_test_parts = [\n    np.ones_like(t_test),\n    t_test,\n    t_test**2,\n    fourier_features(t_test, period=7, order=3),\n    fourier_features(t_test, period=365.25, order=5)\n]\nX_test = np.column_stack(X_test_parts)\nft_forecast = pd.Series(X_test @ beta, index=test.index)\n\n# Metrics\nprint(\"Fourier - RMSE:\", rmse(y_test, ft_forecast), \"MAE:\", mae(y_test, ft_forecast), \"MAPE:\", mape(y_test, ft_forecast))\n\n# Keep residual std for simple CIs later\nresid = y_tr - (X_train @ beta)\nsigma = float(np.std(resid, ddof=1))\nsigma",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3679dc",
      "metadata": {},
      "source": "\nmetrics = pd.DataFrame({\n    'model': ['Naive', 'SeasonalNaive', 'MA(7)', 'SES', 'FourierTrend'],\n    'RMSE': [\n        rmse(y_test, pd.Series(y_train.iloc[-1], index=test.index)),\n        rmse(y_test, pd.Series(seasonal_naive.values, index=test.index)),\n        rmse(y_test, ma_forecast),\n        rmse(y_test, ses_forecast),\n        rmse(y_test, ft_forecast),\n    ],\n    'MAE': [\n        mae(y_test, pd.Series(y_train.iloc[-1], index=test.index)),\n        mae(y_test, pd.Series(seasonal_naive.values, index=test.index)),\n        mae(y_test, ma_forecast),\n        mae(y_test, ses_forecast),\n        mae(y_test, ft_forecast),\n    ],\n    'MAPE': [\n        mape(y_test, pd.Series(y_train.iloc[-1], index=test.index)),\n        mape(y_test, pd.Series(seasonal_naive.values, index=test.index)),\n        mape(y_test, ma_forecast),\n        mape(y_test, ses_forecast),\n        mape(y_test, ft_forecast),\n    ]\n}).sort_values('RMSE').reset_index(drop=True)\n\ndisplay(metrics)\n\nplt.figure(figsize=(8,3))\nplt.bar(metrics['model'], metrics['RMSE'])\nplt.title('RMSE by Model (Lower is Better)')\nplt.xlabel('Model')\nplt.ylabel('RMSE')\nplt.grid(True, axis='y')\nplt.show()",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "63a1a48c",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Visualize forecasts on the test window\nWe'll overlay the test period with a few model predictions.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f816e7d5",
      "metadata": {},
      "source": "\nplt.figure(figsize=(10,4))\nplt.plot(y_test.index, y_test.values, label='Actual')\nplt.plot(test.index, seasonal_naive.values, label='Seasonal Naive')\nplt.plot(test.index, ma_forecast.values, label='MA(7)')\nplt.plot(test.index, ses_forecast.values, label=f'SES (alpha={best_alpha:.2f})')\nplt.plot(test.index, ft_forecast.values, label='Fourier+Trend')\nplt.title('Test Period: Actual vs Forecasts')\nplt.xlabel('Date')\nplt.ylabel('y')\nplt.grid(True)\nplt.legend()\nplt.show()",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b875aaa7",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "\n## Forecast the next 90 days\nWe'll pick the **best RMSE** model and produce a 90-day forecast with simple confidence bands where applicable.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57a63fd",
      "metadata": {},
      "source": "\n# Choose best by RMSE\nbest_model = metrics.iloc[0]['model']\nprint(\"Best model by RMSE:\", best_model)\n\nfuture_h = 90\nlast_date = df.index[-1]\nfuture_idx = pd.date_range(last_date + pd.Timedelta(days=1), periods=future_h, freq='D')\n\nif best_model == 'FourierTrend':\n    # Build X for future\n    t_future = np.arange(len(df), len(df)+future_h)\n    X_future_parts = [\n        np.ones_like(t_future),\n        t_future,\n        t_future**2,\n        fourier_features(t_future, period=7, order=3),\n        fourier_features(t_future, period=365.25, order=5)\n    ]\n    X_future = np.column_stack(X_future_parts)\n    future_pred = X_future @ beta\n    # Simple CI from train residual std (not accounting for parameter uncertainty)\n    upper = future_pred + 1.96 * sigma\n    lower = future_pred - 1.96 * sigma\n    future_df = pd.DataFrame({'yhat': future_pred, 'yhat_lower': lower, 'yhat_upper': upper}, index=future_idx)\n\nelif best_model == 'SES':\n    # Continue SES forward using last fitted level\n    # Re-train SES using best alpha on full df for a stable final level\n    preds_full, S_final = ses_one_step(df['y'].iloc[:-1], pd.Series([df['y'].iloc[-1]]), best_alpha)\n    level = float(S_final)\n    yhat = np.repeat(level, future_h)\n    # Use test residual std from SES as simple CI\n    ses_resid = y_test.values - ses_forecast.values\n    ses_sigma = float(np.std(ses_resid, ddof=1))\n    upper = yhat + 1.96 * ses_sigma\n    lower = yhat - 1.96 * ses_sigma\n    future_df = pd.DataFrame({'yhat': yhat, 'yhat_lower': lower, 'yhat_upper': upper}, index=future_idx)\n\nelif best_model == 'MA(7)':\n    # Roll forward using last 7 observed values\n    hist = df['y'].copy()\n    preds = []\n    for _ in range(future_h):\n        if len(hist) >= 7:\n            preds.append(hist.iloc[-7:].mean())\n        else:\n            preds.append(hist.mean())\n        # simulate observing the prediction (for rolling context); optional\n        hist = pd.concat([hist, pd.Series([preds[-1]], index=[hist.index[-1] + pd.Timedelta(days=1)])])\n    ma_resid = y_test.values - ma_forecast.values\n    s = float(np.std(ma_resid, ddof=1))\n    upper = np.array(preds) + 1.96 * s\n    lower = np.array(preds) - 1.96 * s\n    future_df = pd.DataFrame({'yhat': preds, 'yhat_lower': lower, 'yhat_upper': upper}, index=future_idx)\n\nelif best_model == 'SeasonalNaive':\n    # Repeat last week's pattern\n    future_vals = []\n    hist = df['y'].copy()\n    for i in range(future_h):\n        ref = hist.index[-7]\n        future_vals.append(hist.loc[ref])\n        hist = pd.concat([hist, pd.Series([future_vals[-1]], index=[hist.index[-1] + pd.Timedelta(days=1)])])\n    sn_resid = y_test.values - seasonal_naive.values\n    s = float(np.std(sn_resid, ddof=1))\n    upper = np.array(future_vals) + 1.96 * s\n    lower = np.array(future_vals) - 1.96 * s\n    future_df = pd.DataFrame({'yhat': future_vals, 'yhat_lower': lower, 'yhat_upper': upper}, index=future_idx)\n\nelse:  # Naive\n    last = df['y'].iloc[-1]\n    yhat = np.repeat(last, future_h)\n    nv_resid = y_test.values - naive_forecast.values\n    s = float(np.std(nv_resid, ddof=1))\n    upper = yhat + 1.96 * s\n    lower = yhat - 1.96 * s\n    future_df = pd.DataFrame({'yhat': yhat, 'yhat_lower': lower, 'yhat_upper': upper}, index=future_idx)\n\n# Plot\nplt.figure(figsize=(10,4))\nplt.plot(df.index[-180:], df['y'].iloc[-180:], label='History (last 180d)')\nplt.plot(future_df.index, future_df['yhat'], label='Forecast')\nplt.fill_between(future_df.index, future_df['yhat_lower'], future_df['yhat_upper'], alpha=0.2, label='~95% Interval')\nplt.title(f'Next {future_h} Days Forecast â€” {best_model}')\nplt.xlabel('Date')\nplt.ylabel('y')\nplt.grid(True)\nplt.legend()\nplt.show()\n",
      "outputs": []
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}