{
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    },
    "lastEditStatus": {
      "notebookId": "v53fh2ft5kiqmpd6l7pu",
      "authorId": "392143379641",
      "authorName": "AALUSI",
      "authorEmail": "annissa.alusi@snowflake.com",
      "sessionId": "1085a96e-b71d-426f-9b68-d15734aa00b8",
      "lastEditTime": 1756574934662
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "id": "9e2a20ec-4274-4171-a38c-791df4dafdc1",
      "metadata": {
        "language": "sql",
        "resultVariableName": "cell1"
      },
      "source": "USE SNOWPUBLIC.NOTEBOOKS;\nUSE ROLE PUBLIC;\n\nCREATE FILE FORMAT IF NOT EXISTS csvformat2 \n    SKIP_HEADER = 1 \n    TYPE = 'CSV';\n\n\n-- create external stage with the csv format to stage the diamonds dataset\nCREATE STAGE IF NOT EXISTS diamond_assets \n    FILE_FORMAT = csvformat2 \n    URL = 's3://sfquickstarts/intro-to-machine-learning-with-snowpark-ml-for-python/diamonds.csv';\n\nCREATE OR REPLACE TABLE SNOWPUBLIC.NOTEBOOKS.DIAMONDS2 (\n\tCARAT NUMBER(38,2),\n\tCUT VARCHAR(16777216),\n\tCOLOR VARCHAR(16777216),\n\tCLARITY VARCHAR(16777216),\n\tDEPTH NUMBER(38,1),\n\t\"TABLE\" NUMBER(38,1),\n\tPRICE NUMBER(38,0),\n\tX NUMBER(38,2),\n\tY NUMBER(38,2),\n\tZ NUMBER(38,2)\n);\n\nCOPY INTO DIAMONDS2\nFROM @diamond_assets;\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "07e67d82-cb27-4518-b025-b74c117c5637",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Welcome to the Notebooks Container Runtime!\n\nIn this notebook, we will go through the basics of using Notebooks Container Runtime. We will install packages, load data, train a model, and look at logs. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a609d6f-f3de-4b32-9731-1411db287f9f",
      "metadata": {
        "collapsed": false,
        "language": "python"
      },
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Add a query tag to the session. This helps with debugging and performance monitoring.\nsession.query_tag = {\"origin\":\"sf_sit-is\", \"name\":\"aiml_notebooks_container_runtime\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\"}}\n",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "93258291-3823-45d5-8703-aa4e5b5b013e",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "The Container Runtime for Snowflake Notebooks includes pre-installed common packages including SnowparkML and other OSS packages.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6b51bc3-e121-4b6c-a84f-20f04eb1f28a",
      "metadata": {
        "collapsed": false,
        "language": "python"
      },
      "source": "!pip freeze",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "507dda4f-a92a-4144-b715-3c9a5b994eb7",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Notebooks Container Runtime, along with External Access Integrations give us the flexibility to `pip install` packages from anywhere, including popular package repositories such as pypi. You can install whatever packages you need by running `!pip install <package_name>` directly in the Notebook.\n\nWe have configured this notebook to allow pypi urls with an External Access Integration. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01982269-5dac-46a6-8af6-2b495e65862f",
      "metadata": {
        "collapsed": false,
        "language": "python"
      },
      "source": "## Commenting out for now !pip install seaborn",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ce5d7e1e-2323-428b-ad5d-dbab1b0f34a8",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "Just like Notebooks on the Warehouse Runtime, we can intermingle both SQL and Python cells:",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b43cb438-746d-476d-8d00-a5fc4cd67648",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Let's visualize some of our data using the `seaborn` package that we installed above:",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f0f888-3d70-42c4-9071-bc366c861a52",
      "metadata": {
        "collapsed": false,
        "language": "python"
      },
      "source": "diamonds_df = session.table(\"DIAMONDS2\")\ndiamonds_df.show()",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e2849a-df59-45d2-81e1-14b7880601fc",
      "metadata": {
        "collapsed": false,
        "language": "python"
      },
      "source": "from snowflake.ml.data.data_connector import DataConnector\ndata_connector = DataConnector.from_dataframe(diamonds_df)\ndf = data_connector.to_pandas()\n\nimport seaborn as sns\n\n# Create a visualization\nsns.histplot(\n    data=df,\n    x=\"PRICE\"\n)",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3020ac4d-058f-49aa-9686-ca0558d1a97b",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Now, let's train a basic `XGBRegressor` machine learning model. The ML Container Runtime for Snowflake Notebooks includes pre-installed common packages for doing machine learning tasks, including SnowparkML and other OSS packages.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53aad007-803a-4120-b227-596caa842cba",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python"
      },
      "source": "import time\nfrom xgboost import XGBRegressor\n\nCATEGORICAL_COLUMNS = [\"CUT\", \"COLOR\", \"CLARITY\"]\nNUMERICAL_COLUMNS = [\"CARAT\", \"DEPTH\", \"X\", \"Y\", \"Z\"]\nLABEL_COLUMNS = ['PRICE']\n\nmodel = XGBRegressor(max_depth=400)\n\nt0 = time.time()\nmodel.fit(df[NUMERICAL_COLUMNS], df[LABEL_COLUMNS])\nt1 = time.time()\n\nprint(f\"Fit in {t1-t0} seconds.\")",
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "7cdf0eeb-bfac-4908-9b52-d13d74930473",
      "metadata": {
        "language": "python"
      },
      "source": "# Import necessary libraries\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport altair as alt\nfrom xgboost import XGBRegressor\n\n# Train/test split\nX = df[NUMERICAL_COLUMNS]\ny = df[LABEL_COLUMNS]\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Train model\nmodel = XGBRegressor(max_depth=400)\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\n\n# Metrics\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\ntrain_r2 = r2_score(y_train, y_pred_train)\ntest_r2 = r2_score(y_test, y_pred_test)\ntrain_mae = mean_absolute_error(y_train, y_pred_train)\ntest_mae = mean_absolute_error(y_test, y_pred_test)\n\n# ---- Display metrics in a simple matplotlib table ----\nmetrics_df = pd.DataFrame({\n    \"Metric\": [\"RMSE\", \"RÂ²\", \"MAE\"],\n    \"Train\": [train_rmse, train_r2, train_mae],\n    \"Test\": [test_rmse, test_r2, test_mae]\n})\n\nfig, ax = plt.subplots(figsize=(6,2))\nax.axis('off')\ntbl = ax.table(cellText=metrics_df.round(3).values,\n               colLabels=metrics_df.columns,\n               loc='center')\ntbl.auto_set_font_size(False)\ntbl.set_fontsize(10)\ntbl.scale(1.2, 1.2)\nplt.title(\"Model Performance Metrics\", fontsize=12, pad=20)\nplt.show()\n\n# ---- Scatter plot: Predicted vs Actual ----\ntest_results = pd.DataFrame({\n    'Actual Price': y_test['PRICE'].values,\n    'Predicted Price': y_pred_test\n})\n\nscatter_chart = alt.Chart(test_results).mark_circle().encode(\n    x=alt.X('Actual Price', title='Actual Price ($)'),\n    y=alt.Y('Predicted Price', title='Predicted Price ($)')\n).properties(\n    title='Predicted vs Actual Diamond Prices',\n    width=600,\n    height=400\n)\n\nline = alt.Chart(\n    pd.DataFrame({'x': [0, test_results['Actual Price'].max()]})\n).mark_line(color='red', strokeDash=[5, 5]).encode(x='x', y='x')\n\nscatter_chart + line\n\n# ---- Feature Importance plot (matplotlib) ----\nfeature_importance = pd.DataFrame({\n    'Feature': NUMERICAL_COLUMNS,\n    'Importance': model.feature_importances_\n}).sort_values(by=\"Importance\", ascending=False)\n\nplt.figure(figsize=(8,5))\nplt.barh(feature_importance['Feature'], feature_importance['Importance'])\nplt.gca().invert_yaxis()\nplt.xlabel(\"Feature Importance\")\nplt.title(\"Feature Importance\")\nplt.show()\n\n",
      "execution_count": null,
      "outputs": []
    }
  ]
}